{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9384071d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "In Part II, we explored the text data using wordclouds to build an intuition. In this Part, we will first transform our text into a form that is suitable for machine learning modelling. Following that, we will then train a classifier model.\n",
    "\n",
    "As an overview, we will:\n",
    "1. Load our libraries\n",
    "2. Read our text data\n",
    "3. Clean our data even further\n",
    "4. Perform td-idf vectorization\n",
    "5. Train a machine learning model\n",
    "6. Tune the dataset and retrain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0024514",
   "metadata": {},
   "source": [
    "### Step 1: Import libraries\n",
    "Import the following libraries:\n",
    "1. pandas as pd\n",
    "2. STOPWORDS from wordcloud\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e5ec625d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Import the libraries\n",
    "import pandas as pd\n",
    "from wordcloud import STOPWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce93e52d",
   "metadata": {},
   "source": [
    "### Step 2: Read your CSV from Part I\n",
    "Import the CSV that we exported at the end of Part I. \n",
    "Making sure that our resulting DataFrame has 2,286 rows and 3 columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7007547",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Definition</th>\n",
       "      <th>is_misogyny</th>\n",
       "      <th>cleaned_definition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ur gonna die... queer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ur gonna die queer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valuptuous man boobs.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>valuptuous man boobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variation of brother.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>variation of brother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very impressive penis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>very impressive penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What I call my penis.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what i call my penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>A women who is \"easy\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a women who is easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>Any hot/ sexy chicks.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>any hot sexy chicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>Any vaginal secretion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>any vaginal secretion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>Person who slaps hoes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>person who slaps hoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>That hoe out there!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>that hoe out there</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Definition  is_misogyny     cleaned_definition\n",
       "0     Ur gonna die... queer          0.0     ur gonna die queer\n",
       "1     Valuptuous man boobs.          0.0   valuptuous man boobs\n",
       "2     Variation of brother.          0.0   variation of brother\n",
       "3     Very impressive penis          0.0  very impressive penis\n",
       "4     What I call my penis.          0.0   what i call my penis\n",
       "...                     ...          ...                    ...\n",
       "2281  A women who is \"easy\"          1.0    a women who is easy\n",
       "2282  Any hot/ sexy chicks.          1.0    any hot sexy chicks\n",
       "2283  Any vaginal secretion          1.0  any vaginal secretion\n",
       "2284  Person who slaps hoes          1.0  person who slaps hoes\n",
       "2285  That hoe out there!!!          1.0     that hoe out there\n",
       "\n",
       "[2286 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 2: Read the CSV\n",
    "df = pd.read_csv('CleanedMisogyny.csv', usecols = ['Definition', 'is_misogyny', 'cleaned_definition'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22281173",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "### Step 3: Create a new column without stopwords\n",
    "Using STOPWORDS from the WordCloud library, we will remove stopwords from the text in the 'cleaned_definition' column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a30e268",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\contr\\AppData\\Local\\Temp\\ipykernel_19524\\3755311153.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['cleaned_definition_nostop'] = df['cleaned_definition'].str.replace(pat, '')\n",
      "C:\\Users\\contr\\AppData\\Local\\Temp\\ipykernel_19524\\3755311153.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  df['cleaned_definition_nostop'] = df['cleaned_definition_nostop'].str.replace(r'\\s+', ' ')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Definition</th>\n",
       "      <th>is_misogyny</th>\n",
       "      <th>cleaned_definition</th>\n",
       "      <th>cleaned_definition_nostop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ur gonna die... queer</td>\n",
       "      <td>0.0</td>\n",
       "      <td>ur gonna die queer</td>\n",
       "      <td>ur gonna die queer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Valuptuous man boobs.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>valuptuous man boobs</td>\n",
       "      <td>valuptuous man boobs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Variation of brother.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>variation of brother</td>\n",
       "      <td>variation brother</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Very impressive penis</td>\n",
       "      <td>0.0</td>\n",
       "      <td>very impressive penis</td>\n",
       "      <td>impressive penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What I call my penis.</td>\n",
       "      <td>0.0</td>\n",
       "      <td>what i call my penis</td>\n",
       "      <td>call penis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>A women who is \"easy\"</td>\n",
       "      <td>1.0</td>\n",
       "      <td>a women who is easy</td>\n",
       "      <td>women easy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>Any hot/ sexy chicks.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>any hot sexy chicks</td>\n",
       "      <td>hot sexy chicks</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>Any vaginal secretion</td>\n",
       "      <td>1.0</td>\n",
       "      <td>any vaginal secretion</td>\n",
       "      <td>vaginal secretion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>Person who slaps hoes</td>\n",
       "      <td>1.0</td>\n",
       "      <td>person who slaps hoes</td>\n",
       "      <td>person slaps hoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>That hoe out there!!!</td>\n",
       "      <td>1.0</td>\n",
       "      <td>that hoe out there</td>\n",
       "      <td>hoe</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Definition  is_misogyny     cleaned_definition  \\\n",
       "0     Ur gonna die... queer          0.0     ur gonna die queer   \n",
       "1     Valuptuous man boobs.          0.0   valuptuous man boobs   \n",
       "2     Variation of brother.          0.0   variation of brother   \n",
       "3     Very impressive penis          0.0  very impressive penis   \n",
       "4     What I call my penis.          0.0   what i call my penis   \n",
       "...                     ...          ...                    ...   \n",
       "2281  A women who is \"easy\"          1.0    a women who is easy   \n",
       "2282  Any hot/ sexy chicks.          1.0    any hot sexy chicks   \n",
       "2283  Any vaginal secretion          1.0  any vaginal secretion   \n",
       "2284  Person who slaps hoes          1.0  person who slaps hoes   \n",
       "2285  That hoe out there!!!          1.0     that hoe out there   \n",
       "\n",
       "     cleaned_definition_nostop  \n",
       "0           ur gonna die queer  \n",
       "1         valuptuous man boobs  \n",
       "2            variation brother  \n",
       "3             impressive penis  \n",
       "4                   call penis  \n",
       "...                        ...  \n",
       "2281                women easy  \n",
       "2282           hot sexy chicks  \n",
       "2283         vaginal secretion  \n",
       "2284         person slaps hoes  \n",
       "2285                      hoe   \n",
       "\n",
       "[2286 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Remove stopwords from the text in 'cleaned_definition'\n",
    "pat = r'\\b(?:{})\\b'.format('|'.join(STOPWORDS))\n",
    "df['cleaned_definition_nostop'] = df['cleaned_definition'].str.replace(pat, '')\n",
    "df['cleaned_definition_nostop'] = df['cleaned_definition_nostop'].str.replace(r'\\s+', ' ')\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b083b84f",
   "metadata": {},
   "source": [
    "### Step 4: Import TfidfVectorizer\n",
    "To prepare our data into a form that will be usable for machine learning, we will turn our text data into a binary vector. \n",
    "\n",
    "Term frequency-inverse document frequecy (Tf-idf) is a score that highlights words that are more interesting, i.e. words that occur in a document but not across many documents.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "232b7800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b5648b8",
   "metadata": {},
   "source": [
    "### Step 5: Vectorize your 'cleaned_definition_nostop'\n",
    "Time to vectorize the 'cleaned_definiton_nostop' column and get each word's tf-idf score.\n",
    "\n",
    "It works like this:\n",
    "1. Assign a variable with the TfidfVectorize object\n",
    "2. Use the .fit_transform method from the object on the column values\n",
    "\n",
    "The result is a sparse matrix (not a DataFrame yet). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "73a88be0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2286x16269 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 53506 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 5a: Declare your TfidVectorizer object\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Step 5b: Perform a fit_transform method with the 'cleaned_definition_nostop' column values\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "vectorised_def"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e993d3ef",
   "metadata": {},
   "source": [
    "### Step 6: Turn the sparse matrix into a DataFrame\n",
    "The sparse matrix data type happens because we need to tokenize each word and set it up as columns. Since the resulting matrix can be potentially huge, the data object is created for loading efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "53bd6872",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>010</th>\n",
       "      <th>02</th>\n",
       "      <th>034</th>\n",
       "      <th>04</th>\n",
       "      <th>0702pm</th>\n",
       "      <th>0708pm</th>\n",
       "      <th>07rnrntheir</th>\n",
       "      <th>095lbsrnbirthday</th>\n",
       "      <th>0chan</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>ûïsight</th>\n",
       "      <th>ûïsuspicious</th>\n",
       "      <th>ûïthe</th>\n",
       "      <th>ûïtrippin</th>\n",
       "      <th>ûïworld</th>\n",
       "      <th>ûò</th>\n",
       "      <th>ûònounnn1</th>\n",
       "      <th>ûòverb</th>\n",
       "      <th>ûòverbnn1rnto</th>\n",
       "      <th>ûóhe</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286 rows × 16269 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      010   02  034   04  0702pm  0708pm  07rnrntheir  095lbsrnbirthday  \\\n",
       "0     0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "1     0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "2     0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "3     0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "4     0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "...   ...  ...  ...  ...     ...     ...          ...               ...   \n",
       "2281  0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "2282  0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "2283  0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "2284  0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "2285  0.0  0.0  0.0  0.0     0.0     0.0          0.0               0.0   \n",
       "\n",
       "      0chan   10  ...  ûïsight  ûïsuspicious  ûïthe  ûïtrippin  ûïworld   ûò  \\\n",
       "0       0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "1       0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "2       0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "3       0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "4       0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "...     ...  ...  ...      ...           ...    ...        ...      ...  ...   \n",
       "2281    0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "2282    0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "2283    0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "2284    0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "2285    0.0  0.0  ...      0.0           0.0    0.0        0.0      0.0  0.0   \n",
       "\n",
       "      ûònounnn1  ûòverb  ûòverbnn1rnto  ûóhe  \n",
       "0           0.0     0.0            0.0   0.0  \n",
       "1           0.0     0.0            0.0   0.0  \n",
       "2           0.0     0.0            0.0   0.0  \n",
       "3           0.0     0.0            0.0   0.0  \n",
       "4           0.0     0.0            0.0   0.0  \n",
       "...         ...     ...            ...   ...  \n",
       "2281        0.0     0.0            0.0   0.0  \n",
       "2282        0.0     0.0            0.0   0.0  \n",
       "2283        0.0     0.0            0.0   0.0  \n",
       "2284        0.0     0.0            0.0   0.0  \n",
       "2285        0.0     0.0            0.0   0.0  \n",
       "\n",
       "[2286 rows x 16269 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 6: Convert the sparse matrix into a DataFrame\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "df_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb361e8f",
   "metadata": {},
   "source": [
    "### Step 7: Import machine learning libraries\n",
    "Import the following machine learning libraries:\n",
    "1. train_test_split from sklearn.model_selection\n",
    "2. DummyClassifier from sklearn.dummy\n",
    "3. LogisticRegression from sklearn.linear_model\n",
    "4. DecisionTreeClassifier from sklearn.tree\n",
    "5. RandomForestClassifier from sklearn.ensemble\n",
    "6. f1_score from sklearn.metrics\n",
    "7. confusion_matrix from sklearn.metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c0e8fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 7: Import your ML libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8b301",
   "metadata": {},
   "source": [
    "### Step 8: Prepare the independent and dependent variables\n",
    "Now that we have everything done, let's prepare our independent variables (the TF-IDF DataFrame and the dependent variable - 'is_misogyny'. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3b620e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 8: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ff4261",
   "metadata": {},
   "source": [
    "### Step 9: Split your indepedent and dependent variables into train and test sets\n",
    "We'll be using a 80/20 split for train and test set respectively, using the train_test_split function, stratified by y. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6a4d6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 9: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a4f30c8",
   "metadata": {},
   "source": [
    "### Step 10: Train a DummyClassifier model\n",
    "This is what we'll need to do:\n",
    "1. Start with a model\n",
    "2. Declare a variable, and store the model in it\n",
    "3. Fit the training data into the instantiated model\n",
    "4. Declare a variable that contains predictions from the model we just trained, using the train dataset (X_test)\n",
    "5. Print the f1_score between the actual y values and the predictions\n",
    "6. Print the confusion matrix between the two values\n",
    "\n",
    "We will start with DummyClassifier to establish the baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "446b84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 10a: Declare a variable to store the DummyClassifier model\n",
    "dummy_cls = DummyClassifier()\n",
    "\n",
    "# Step 10b: Fit your train dataset\n",
    "dummy_cls.fit(X_train, y_train)\n",
    "\n",
    "# Step 10c: Declare a variable and store your predictions that you make with your model using X test data\n",
    "predicted = dummy_cls.predict(X_test)\n",
    "\n",
    "# Step 10d: Print the f1_score between the y test and prediction\n",
    "F1 = f1_score(y_test, predicted)\n",
    "\n",
    "# Step 10e: Print the confusion matrix using the y test and prediction\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23d3a57a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dummy Classifier\n",
      "================\n",
      "F1 Score: 0.0\n",
      "\n",
      "Confusion Matrix\n",
      "[[313   0]\n",
      " [259   0]]\n"
     ]
    }
   ],
   "source": [
    "model_type = \"Dummy Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f23195",
   "metadata": {},
   "source": [
    "### Step 11: Train a LogisticRegression model\n",
    "Train a LogisticRegression model and assess its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9ce672ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 11a: Declare a variable to store the LogisticRegression model\n",
    "logreg = LogisticRegression()\n",
    "\n",
    "# Step 11b: Fit your train dataset\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Step 11c: Declare a variable and store your predictions that you make with your model using X test data\n",
    "predicted = logreg.predict(X_test)\n",
    "\n",
    "# Step 11d: Print the f1_score between the y test and prediction\n",
    "F1 = f1_score(y_test, predicted)\n",
    "\n",
    "# Step 11e: Print the confusion matrix using the y test and prediction\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b44c84a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "===================\n",
      "F1 Score: 0.7699316628701595\n",
      "\n",
      "Confusion Matrix\n",
      "[[302  11]\n",
      " [ 90 169]]\n"
     ]
    }
   ],
   "source": [
    "model_type = \"Logistic Regression\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69817ae",
   "metadata": {},
   "source": [
    "### Step 12: Train a DecisionTreeClassifier model\n",
    "Let's see if using DecisionTree classifier changes things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0136ef63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 12a: Train a DecisionTreeClassifer model\n",
    "dtree = DecisionTreeClassifier()\n",
    "\n",
    "# Step 12b: Fit your train dataset\n",
    "dtree.fit(X_train, y_train)\n",
    "\n",
    "# Step 12c: Declare a variable and store your predictions that you make with your model using X test data\n",
    "predicted = dtree.predict(X_test)\n",
    "\n",
    "# Step 12d: Print the f1_score between the y test and prediction\n",
    "F1 = f1_score(y_test, predicted)\n",
    "\n",
    "# Step 12e: Print the confusion matrix using the y test and prediction\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e3955fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier\n",
      "========================\n",
      "F1 Score: 0.8352490421455939\n",
      "\n",
      "Confusion Matrix\n",
      "[[268  45]\n",
      " [ 41 218]]\n"
     ]
    }
   ],
   "source": [
    "model_type = \"Decision Tree Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "292e0a2c",
   "metadata": {},
   "source": [
    "### Step 13: Train a RandomForestClassifier model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af93027e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 13a: Train a RandomForestClassifier model\n",
    "rforest = RandomForestClassifier()\n",
    "\n",
    "# Step 13b: Fit your train dataset\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "# Step 13c: Declare a variable and store your predictions that you make with your model using X test data\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 13d: Print the f1_score between the y test and prediction\n",
    "F1 = f1_score(y_test, predicted)\n",
    "\n",
    "# Step 13e: Print the confusion matrix using the y test and prediction\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15b81c94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8336842105263158\n",
      "\n",
      "Confusion Matrix\n",
      "[[295  18]\n",
      " [ 61 198]]\n"
     ]
    }
   ],
   "source": [
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15709913",
   "metadata": {},
   "source": [
    "### Step 14: Get feature importance from model and create a DataFrame\n",
    "The results from the RandomForest training yielded the best performance based on the F1 Scores. Let's take a look at what features are important in its classifiying ability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "15bd85d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15317</th>\n",
       "      <td>vagina</td>\n",
       "      <td>0.060023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5289</th>\n",
       "      <td>female</td>\n",
       "      <td>0.044330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11318</th>\n",
       "      <td>pussy</td>\n",
       "      <td>0.033991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15937</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.028414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10400</th>\n",
       "      <td>penis</td>\n",
       "      <td>0.015828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7049</th>\n",
       "      <td>importance</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7051</th>\n",
       "      <td>importantly</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7052</th>\n",
       "      <td>importantrn2</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>imported</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16268</th>\n",
       "      <td>ûóhe</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16269 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            feature  importance\n",
       "15317        vagina    0.060023\n",
       "5289         female    0.044330\n",
       "11318         pussy    0.033991\n",
       "15937         woman    0.028414\n",
       "10400         penis    0.015828\n",
       "...             ...         ...\n",
       "7049     importance    0.000000\n",
       "7051    importantly    0.000000\n",
       "7052   importantrn2    0.000000\n",
       "7053       imported    0.000000\n",
       "16268          ûóhe    0.000000\n",
       "\n",
       "[16269 rows x 2 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 14: Create a DataFrame containing the feature importances of the model and sort \n",
    "\n",
    "# get the feature importances of the random forest model\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# create DataFrame and sort\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "rf_df.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b79f8d",
   "metadata": {},
   "source": [
    "### Step 15: Repeat Steps 5-6 with max_features\n",
    "Turns out we don't really need so many features from vectorization. \n",
    "\n",
    "Let's repeat our vectorization but <strong>limit the number of features extracted to 100</strong> by adding the 'max_features' parameter.\n",
    "\n",
    "It is better to limit the features so that we do not spend too much time training our models and this also avoids overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff301618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>always</th>\n",
       "      <th>another</th>\n",
       "      <th>anyone</th>\n",
       "      <th>anything</th>\n",
       "      <th>around</th>\n",
       "      <th>ass</th>\n",
       "      <th>back</th>\n",
       "      <th>band</th>\n",
       "      <th>best</th>\n",
       "      <th>...</th>\n",
       "      <th>vagina</th>\n",
       "      <th>want</th>\n",
       "      <th>way</th>\n",
       "      <th>well</th>\n",
       "      <th>will</th>\n",
       "      <th>without</th>\n",
       "      <th>woman</th>\n",
       "      <th>women</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      act  always  another  anyone  anything  around  ass  back  band  best  \\\n",
       "0     0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "1     0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "2     0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "3     0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "4     0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "...   ...     ...      ...     ...       ...     ...  ...   ...   ...   ...   \n",
       "2281  0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "2282  0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "2283  0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "2284  0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "2285  0.0     0.0      0.0     0.0       0.0     0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "      ...  vagina  want  way  well  will  without  woman  women  word  world  \n",
       "0     ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "1     ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "2     ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "3     ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "4     ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "...   ...     ...   ...  ...   ...   ...      ...    ...    ...   ...    ...  \n",
       "2281  ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    1.0   0.0    0.0  \n",
       "2282  ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "2283  ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "2284  ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "2285  ...     0.0   0.0  0.0   0.0   0.0      0.0    0.0    0.0   0.0    0.0  \n",
       "\n",
       "[2286 rows x 100 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 15a: Declare TfidVectorizer object, but add the max_features parameter - 100 features\n",
    "vectorizer = TfidfVectorizer(max_features= 100)\n",
    "\n",
    "# Step 15b: Perform a fit_transform method with the 'cleaned_definition_nostop' column values\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "vectorised_def\n",
    "\n",
    "# Step 15c: Convert the sparse matrix into a new DataFrame\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "df_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c5ebe4",
   "metadata": {},
   "source": [
    "### Step 16: Repeat earlier steps\n",
    "Now that we have a new DataFrame, we'll have to:\n",
    "1. Prepare the independent variables (dependent variable remains the same)\n",
    "2. Perform the splitting of the data into train and test\n",
    "3. Train a a Random Forest model\n",
    "4. Perform prediction and assess predictions using f1_score and confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ba349f42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>vagina</td>\n",
       "      <td>0.113629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>female</td>\n",
       "      <td>0.095335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>pussy</td>\n",
       "      <td>0.071784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.060296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>sex</td>\n",
       "      <td>0.035171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>place</td>\n",
       "      <td>0.001953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>anything</td>\n",
       "      <td>0.001952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>never</td>\n",
       "      <td>0.001914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>real</td>\n",
       "      <td>0.001690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>black</td>\n",
       "      <td>0.001596</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance\n",
       "90    vagina    0.113629\n",
       "23    female    0.095335\n",
       "68     pussy    0.071784\n",
       "96     woman    0.060296\n",
       "75       sex    0.035171\n",
       "..       ...         ...\n",
       "67     place    0.001953\n",
       "4   anything    0.001952\n",
       "60     never    0.001914\n",
       "69      real    0.001690\n",
       "11     black    0.001596\n",
       "\n",
       "[100 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 16a: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()\n",
    "\n",
    "# Step 16b: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)\n",
    "\n",
    "# Step 16c: Train a RandomForestClassifier model (or other models)\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 16d: Make a new set of predictions\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 16e: Assess your prediction with f1_score and confusion_matrix\n",
    "F1 = f1_score(y_test, predicted)\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# Step 16f: Get feature importances\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# Step 16g: Check the most important features\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "rf_df.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4d134683",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8168421052631577\n",
      "\n",
      "Confusion Matrix\n",
      "[[291  22]\n",
      " [ 65 194]]\n"
     ]
    }
   ],
   "source": [
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b50dc2",
   "metadata": {},
   "source": [
    "### Step 17: Tweak max_feature values\n",
    "The model with 100 features seems to be worse performing than 16k features. \n",
    "Let's tweak the number of max_features from 100 to higher numbers, in increments of 250."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84667ed2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>act</th>\n",
       "      <th>actually</th>\n",
       "      <th>age</th>\n",
       "      <th>album</th>\n",
       "      <th>almost</th>\n",
       "      <th>although</th>\n",
       "      <th>always</th>\n",
       "      <th>amazing</th>\n",
       "      <th>american</th>\n",
       "      <th>amount</th>\n",
       "      <th>...</th>\n",
       "      <th>word</th>\n",
       "      <th>words</th>\n",
       "      <th>work</th>\n",
       "      <th>world</th>\n",
       "      <th>year</th>\n",
       "      <th>years</th>\n",
       "      <th>yet</th>\n",
       "      <th>youll</th>\n",
       "      <th>young</th>\n",
       "      <th>youre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2281</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2282</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2283</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2284</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2285</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2286 rows × 350 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      act  actually  age  album  almost  although  always  amazing  american  \\\n",
       "0     0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "1     0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "2     0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "3     0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "4     0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "...   ...       ...  ...    ...     ...       ...     ...      ...       ...   \n",
       "2281  0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "2282  0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "2283  0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "2284  0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "2285  0.0       0.0  0.0    0.0     0.0       0.0     0.0      0.0       0.0   \n",
       "\n",
       "      amount  ...  word  words  work  world  year  years  yet  youll  young  \\\n",
       "0        0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "1        0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "2        0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "3        0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "4        0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "...      ...  ...   ...    ...   ...    ...   ...    ...  ...    ...    ...   \n",
       "2281     0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "2282     0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "2283     0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "2284     0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "2285     0.0  ...   0.0    0.0   0.0    0.0   0.0    0.0  0.0    0.0    0.0   \n",
       "\n",
       "      youre  \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "2281    0.0  \n",
       "2282    0.0  \n",
       "2283    0.0  \n",
       "2284    0.0  \n",
       "2285    0.0  \n",
       "\n",
       "[2286 rows x 350 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 17: Continuously tweak the max_features parameter until the performance cannot be further improved\n",
    "# 350 max features\n",
    "vectorizer = TfidfVectorizer(max_features= 350)\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "df_sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6ba0a66a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>vagina</td>\n",
       "      <td>0.102537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>female</td>\n",
       "      <td>0.092480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>pussy</td>\n",
       "      <td>0.057834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.043442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>224</th>\n",
       "      <td>people</td>\n",
       "      <td>0.025933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>town</td>\n",
       "      <td>0.000130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>youll</td>\n",
       "      <td>0.000052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>child</td>\n",
       "      <td>0.000051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>death</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>album</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature  importance\n",
       "324  vagina    0.102537\n",
       "92   female    0.092480\n",
       "239   pussy    0.057834\n",
       "337   woman    0.043442\n",
       "224  people    0.025933\n",
       "..      ...         ...\n",
       "310    town    0.000130\n",
       "347   youll    0.000052\n",
       "49    child    0.000051\n",
       "64    death    0.000014\n",
       "3     album    0.000000\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 17a: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()\n",
    "\n",
    "# Step 17b: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)\n",
    "\n",
    "# Step 17c: Train a RandomForestClassifier model (or other models)\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 17d: Make a new set of predictions\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 17e: Assess your prediction with f1_score and confusion_matrix\n",
    "F1 = f1_score(y_test, predicted)\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# Step 17f: Get feature importances\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# Step 17g: Check the most important features\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "rf_df.sort_values('importance', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3932d26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8530020703933747\n",
      "\n",
      "Confusion Matrix\n",
      "[[295  18]\n",
      " [ 53 206]]\n"
     ]
    }
   ],
   "source": [
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25fde860",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>556</th>\n",
       "      <td>vagina</td>\n",
       "      <td>8.922488e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>female</td>\n",
       "      <td>8.331026e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>pussy</td>\n",
       "      <td>5.343823e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>woman</td>\n",
       "      <td>5.216866e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>dick</td>\n",
       "      <td>2.374427e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>community</td>\n",
       "      <td>5.155622e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>age</td>\n",
       "      <td>1.249667e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>college</td>\n",
       "      <td>1.067871e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>famous</td>\n",
       "      <td>4.432464e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>israel</td>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>600 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature    importance\n",
       "556     vagina  8.922488e-02\n",
       "179     female  8.331026e-02\n",
       "407      pussy  5.343823e-02\n",
       "583      woman  5.216866e-02\n",
       "127       dick  2.374427e-02\n",
       "..         ...           ...\n",
       "102  community  5.155622e-06\n",
       "6          age  1.249667e-06\n",
       "97     college  1.067871e-06\n",
       "172     famous  4.432464e-07\n",
       "261     israel  0.000000e+00\n",
       "\n",
       "[600 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8525252525252526\n",
      "\n",
      "Confusion Matrix\n",
      "[[288  25]\n",
      " [ 48 211]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 600)\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "# Step 17a: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()\n",
    "\n",
    "# Step 17b: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)\n",
    "\n",
    "# Step 17c: Train a RandomForestClassifier model (or other models)\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 17d: Make a new set of predictions\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 17e: Assess your prediction with f1_score and confusion_matrix\n",
    "F1 = f1_score(y_test, predicted)\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# Step 17f: Get feature importances\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# Step 17g: Check the most important features\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "display(rf_df.sort_values('importance', ascending = False))\n",
    "\n",
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "884f4032",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>vagina</td>\n",
       "      <td>0.082936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>female</td>\n",
       "      <td>0.082408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>587</th>\n",
       "      <td>pussy</td>\n",
       "      <td>0.050343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>828</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.046397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>dick</td>\n",
       "      <td>0.023525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>624</th>\n",
       "      <td>rights</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>album</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>osby</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>cars</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>615</th>\n",
       "      <td>released</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>850 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      feature  importance\n",
       "791    vagina    0.082936\n",
       "270    female    0.082408\n",
       "587     pussy    0.050343\n",
       "828     woman    0.046397\n",
       "196      dick    0.023525\n",
       "..        ...         ...\n",
       "624    rights    0.000000\n",
       "16      album    0.000000\n",
       "521      osby    0.000000\n",
       "122      cars    0.000000\n",
       "615  released    0.000000\n",
       "\n",
       "[850 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8727272727272728\n",
      "\n",
      "Confusion Matrix\n",
      "[[293  20]\n",
      " [ 43 216]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 850)\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "# Step 17a: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()\n",
    "\n",
    "# Step 17b: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)\n",
    "\n",
    "# Step 17c: Train a RandomForestClassifier model (or other models)\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 17d: Make a new set of predictions\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 17e: Assess your prediction with f1_score and confusion_matrix\n",
    "F1 = f1_score(y_test, predicted)\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# Step 17f: Get feature importances\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# Step 17g: Check the most important features\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "display(rf_df.sort_values('importance', ascending = False))\n",
    "\n",
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2f734c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>vagina</td>\n",
       "      <td>0.087758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>female</td>\n",
       "      <td>0.082701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>pussy</td>\n",
       "      <td>0.055135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1075</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.043955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>people</td>\n",
       "      <td>0.019680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>prove</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>break</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>748</th>\n",
       "      <td>products</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>stores</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1100 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "1027    vagina    0.087758\n",
       "344     female    0.082701\n",
       "758      pussy    0.055135\n",
       "1075     woman    0.043955\n",
       "689     people    0.019680\n",
       "...        ...         ...\n",
       "1           14    0.000000\n",
       "750      prove    0.000000\n",
       "127      break    0.000000\n",
       "748   products    0.000000\n",
       "921     stores    0.000000\n",
       "\n",
       "[1100 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8385826771653544\n",
      "\n",
      "Confusion Matrix\n",
      "[[277  36]\n",
      " [ 46 213]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 1100)\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "# Step 17a: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()\n",
    "\n",
    "# Step 17b: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)\n",
    "\n",
    "# Step 17c: Train a RandomForestClassifier model (or other models)\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 17d: Make a new set of predictions\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 17e: Assess your prediction with f1_score and confusion_matrix\n",
    "F1 = f1_score(y_test, predicted)\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# Step 17f: Get feature importances\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# Step 17g: Check the most important features\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "display(rf_df.sort_values('importance', ascending = False))\n",
    "\n",
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7159c69c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Miniconda\\envs\\minimal_ds\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1260</th>\n",
       "      <td>vagina</td>\n",
       "      <td>0.085851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>female</td>\n",
       "      <td>0.071937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1320</th>\n",
       "      <td>woman</td>\n",
       "      <td>0.043368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>926</th>\n",
       "      <td>pussy</td>\n",
       "      <td>0.042088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>dick</td>\n",
       "      <td>0.025157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1283</th>\n",
       "      <td>watch</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>900</th>\n",
       "      <td>powers</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>buying</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1002</th>\n",
       "      <td>satan</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>creature</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       feature  importance\n",
       "1260    vagina    0.085851\n",
       "425     female    0.071937\n",
       "1320     woman    0.043368\n",
       "926      pussy    0.042088\n",
       "308       dick    0.025157\n",
       "...        ...         ...\n",
       "1283     watch    0.000000\n",
       "900     powers    0.000000\n",
       "175     buying    0.000000\n",
       "1002     satan    0.000000\n",
       "268   creature    0.000000\n",
       "\n",
       "[1350 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Classifier\n",
      "========================\n",
      "F1 Score: 0.8440748440748441\n",
      "\n",
      "Confusion Matrix\n",
      "[[294  19]\n",
      " [ 56 203]]\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features= 1350)\n",
    "vectorised_def = vectorizer.fit_transform(df['cleaned_definition_nostop'])\n",
    "df_sparse = pd.DataFrame.sparse.from_spmatrix(vectorised_def, columns = vectorizer.get_feature_names())\n",
    "# Step 17a: Prepare your indepedent and independent variables\n",
    "independent_variables = df_sparse\n",
    "dependent_variable = df['is_misogyny'].to_list()\n",
    "\n",
    "# Step 17b: Split your data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(independent_variables, dependent_variable, stratify = dependent_variable)\n",
    "\n",
    "# Step 17c: Train a RandomForestClassifier model (or other models)\n",
    "rforest = RandomForestClassifier()\n",
    "rforest.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "# Step 17d: Make a new set of predictions\n",
    "predicted = rforest.predict(X_test)\n",
    "\n",
    "# Step 17e: Assess your prediction with f1_score and confusion_matrix\n",
    "F1 = f1_score(y_test, predicted)\n",
    "cfn_matrix = confusion_matrix(y_test, predicted)\n",
    "\n",
    "# Step 17f: Get feature importances\n",
    "importances = rforest.feature_importances_\n",
    "\n",
    "# Step 17g: Check the most important features\n",
    "rf_df = pd.DataFrame(data = {'feature': independent_variables.columns, 'importance': importances})\n",
    "display(rf_df.sort_values('importance', ascending = False))\n",
    "\n",
    "model_type = \"Random Forest Classifier\"\n",
    "print(model_type)\n",
    "print('=' * len(model_type))\n",
    "print(\"F1 Score: {}\".format(F1))\n",
    "print('')\n",
    "print('Confusion Matrix')\n",
    "print(cfn_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc356654",
   "metadata": {},
   "source": [
    "Evaluating each model's performance, it seems that when max_features is set to 850, we get the best F1 Score on the Random Forest Classifier Model at 0.872.\n",
    "\n",
    "Beyond 850 max_features, F1 Score starts to drop to 0.839 at 1100 max_features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94e391a2",
   "metadata": {},
   "source": [
    "## Model testing\n",
    "### Step 18: Test a few strings and see if they are misogynist or not\n",
    "Come up with a few strings and see if they are misogynist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cec278c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 18a: Declare a few strings containing mock definitions \n",
    "string_1 = 'princess'\n",
    "string_2 = 'dude'\n",
    "string_3 = 'bitch'\n",
    "\n",
    "# Step 18b: Append the strings into a list\n",
    "test_list = [string_1, string_2, string_3]\n",
    "\n",
    "# Step 18c: .transform these strings using the TfidfVectorizer object\n",
    "vect_test = vectorizer.transform(test_list)\n",
    "\n",
    "# Step 18d: Use the trained RandomForest model to predict what class your strings are\n",
    "rforest.predict(vect_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
